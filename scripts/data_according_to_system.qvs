Trace
===============================================================
    DATA ACCORDING TO SYSTEM
    Script generated by Qlik Script Generator
===============================================================
;
Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__addresses
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__addresses.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [address_id],
    [state_province_id],
    [address_line1],
    [address_line2],
    [city],
    [postal_code],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__addresses]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([address_id]) As [address_id],
    Text([state_province_id]) As [state_province_id],
    Text([address_line1]) As [address_line1],
    Text([address_line2]) As [address_line2],
    Text([city]) As [city],
    Text([postal_code]) As [postal_code],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__addresses.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__addresses'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__addresses])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__addresses] With 'Street address information for customers, employees, and vendors.';

    Trace Commenting fields...;
    Comment Field [address_id] With 'Primary key for Address records.';
    Comment Field [state_province_id] With 'Unique identification number for the state or province. Foreign key to StateProvince table.';
    Comment Field [address_line1] With 'First street address line.';
    Comment Field [address_line2] With 'Second street address line.';
    Comment Field [city] With 'Name of the city.';
    Comment Field [postal_code] With 'Postal code for the street address.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__addresses] Into [$(val__qvd_path__das)/raw__adventure_works__addresses.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__addresses];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__address_types
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__address_types.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [address_type_id],
    [name],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__address_types]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([address_type_id]) As [address_type_id],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__address_types.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__address_types'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__address_types])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__address_types] With 'Types of addresses stored in the Address table.';

    Trace Commenting fields...;
    Comment Field [address_type_id] With 'Primary key for AddressType records.';
    Comment Field [name] With 'Address type description. For example, Billing, Home, or Shipping.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__address_types] Into [$(val__qvd_path__das)/raw__adventure_works__address_types.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__address_types];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__bill_of_materials
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__bill_of_materials.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [bill_of_materials_id],
    [component_id],
    [product_assembly_id],
    [bomlevel],
    [end_date],
    [per_assembly_qty],
    [start_date],
    [unit_measure_code],
    [modified_date]
)
;

[raw__adventure_works__bill_of_materials]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([bill_of_materials_id]) As [bill_of_materials_id],
    Text([component_id]) As [component_id],
    Text([product_assembly_id]) As [product_assembly_id],
    Text([bomlevel]) As [bomlevel],
    Text([end_date]) As [end_date],
    Text([per_assembly_qty]) As [per_assembly_qty],
    Text([start_date]) As [start_date],
    Text([unit_measure_code]) As [unit_measure_code],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__bill_of_materials.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__bill_of_materials'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__bill_of_materials])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__bill_of_materials] With 'Items required to make bicycles and bicycle subassemblies. It identifies the hierarchical relationship between a parent product and its components.';

    Trace Commenting fields...;
    Comment Field [bill_of_materials_id] With 'Primary key for BillOfMaterials records.';
    Comment Field [component_id] With 'Component identification number. Foreign key to Product.ProductID.';
    Comment Field [product_assembly_id] With 'Parent product identification number. Foreign key to Product.ProductID.';
    Comment Field [bomlevel] With 'Indicates the depth the component is from its parent (AssemblyID).';
    Comment Field [end_date] With 'Date the component stopped being used in the assembly item.';
    Comment Field [per_assembly_qty] With 'Quantity of the component needed to create the assembly.';
    Comment Field [start_date] With 'Date the component started being used in the assembly item.';
    Comment Field [unit_measure_code] With 'Standard code identifying the unit of measure for the quantity.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__bill_of_materials] Into [$(val__qvd_path__das)/raw__adventure_works__bill_of_materials.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__bill_of_materials];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__business_entity_addresses
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__business_entity_addresses.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [address_id],
    [address_type_id],
    [business_entity_id],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__business_entity_addresses]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([address_id]) As [address_id],
    Text([address_type_id]) As [address_type_id],
    Text([business_entity_id]) As [business_entity_id],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__business_entity_addresses.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__business_entity_addresses'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__business_entity_addresses])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__business_entity_addresses] With 'Cross-reference table mapping customers, vendors, and employees to their addresses.';

    Trace Commenting fields...;
    Comment Field [address_id] With 'Primary key. Foreign key to Address.AddressID.';
    Comment Field [address_type_id] With 'Primary key. Foreign key to AddressType.AddressTypeID.';
    Comment Field [business_entity_id] With 'Primary key. Foreign key to BusinessEntity.BusinessEntityID.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__business_entity_addresses] Into [$(val__qvd_path__das)/raw__adventure_works__business_entity_addresses.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__business_entity_addresses];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__business_entity_contacts
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__business_entity_contacts.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [contact_type_id],
    [person_id],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__business_entity_contacts]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([contact_type_id]) As [contact_type_id],
    Text([person_id]) As [person_id],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__business_entity_contacts.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__business_entity_contacts'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__business_entity_contacts])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__business_entity_contacts] With 'Cross-reference table mapping stores, vendors, and employees to people.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key. Foreign key to BusinessEntity.BusinessEntityID.';
    Comment Field [contact_type_id] With 'Primary key. Foreign key to ContactType.ContactTypeID.';
    Comment Field [person_id] With 'Primary key. Foreign key to Person.BusinessEntityID.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__business_entity_contacts] Into [$(val__qvd_path__das)/raw__adventure_works__business_entity_contacts.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__business_entity_contacts];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__contact_types
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__contact_types.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [contact_type_id],
    [name],
    [modified_date]
)
;

[raw__adventure_works__contact_types]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([contact_type_id]) As [contact_type_id],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__contact_types.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__contact_types'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__contact_types])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__contact_types] With 'Lookup table containing the types of business entity contacts.';

    Trace Commenting fields...;
    Comment Field [contact_type_id] With 'Primary key for ContactType records.';
    Comment Field [name] With 'Contact type description.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__contact_types] Into [$(val__qvd_path__das)/raw__adventure_works__contact_types.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__contact_types];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__country_regions
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__country_regions.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [country_region_code],
    [name],
    [modified_date]
)
;

[raw__adventure_works__country_regions]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([country_region_code]) As [country_region_code],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__country_regions.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__country_regions'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__country_regions])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__country_regions] With 'Lookup table containing the ISO standard codes for countries and regions.';

    Trace Commenting fields...;
    Comment Field [country_region_code] With 'ISO standard code for countries and regions.';
    Comment Field [name] With 'Country or region name.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__country_regions] Into [$(val__qvd_path__das)/raw__adventure_works__country_regions.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__country_regions];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__credit_cards
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__credit_cards.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [credit_card_id],
    [card_number],
    [card_type],
    [exp_month],
    [exp_year],
    [modified_date]
)
;

[raw__adventure_works__credit_cards]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([credit_card_id]) As [credit_card_id],
    Text([card_number]) As [card_number],
    Text([card_type]) As [card_type],
    Text([exp_month]) As [exp_month],
    Text([exp_year]) As [exp_year],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__credit_cards.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__credit_cards'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__credit_cards])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__credit_cards] With 'Customer credit card information.';

    Trace Commenting fields...;
    Comment Field [credit_card_id] With 'Primary key for CreditCard records.';
    Comment Field [card_number] With 'Credit card number.';
    Comment Field [card_type] With 'Credit card name.';
    Comment Field [exp_month] With 'Credit card expiration month.';
    Comment Field [exp_year] With 'Credit card expiration year.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__credit_cards] Into [$(val__qvd_path__das)/raw__adventure_works__credit_cards.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__credit_cards];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__cultures
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__cultures.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [culture_id],
    [name],
    [modified_date]
)
;

[raw__adventure_works__cultures]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([culture_id]) As [culture_id],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__cultures.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__cultures'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__cultures])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__cultures] With 'Lookup table containing the languages in which some AdventureWorks data is stored.';

    Trace Commenting fields...;
    Comment Field [culture_id] With 'Primary key for Culture records.';
    Comment Field [name] With 'Culture description.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__cultures] Into [$(val__qvd_path__das)/raw__adventure_works__cultures.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__cultures];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__currencies
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__currencies.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [currency_code],
    [name],
    [modified_date]
)
;

[raw__adventure_works__currencies]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([currency_code]) As [currency_code],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__currencies.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__currencies'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__currencies])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__currencies] With 'Lookup table containing standard ISO currencies.';

    Trace Commenting fields...;
    Comment Field [currency_code] With 'The ISO code for the Currency.';
    Comment Field [name] With 'Currency name.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__currencies] Into [$(val__qvd_path__das)/raw__adventure_works__currencies.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__currencies];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__currency_rates
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__currency_rates.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [currency_rate_id],
    [average_rate],
    [currency_rate_date],
    [end_of_day_rate],
    [from_currency_code],
    [to_currency_code],
    [modified_date]
)
;

[raw__adventure_works__currency_rates]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([currency_rate_id]) As [currency_rate_id],
    Text([average_rate]) As [average_rate],
    Text([currency_rate_date]) As [currency_rate_date],
    Text([end_of_day_rate]) As [end_of_day_rate],
    Text([from_currency_code]) As [from_currency_code],
    Text([to_currency_code]) As [to_currency_code],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__currency_rates.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__currency_rates'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__currency_rates])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__currency_rates] With 'Currency exchange rates.';

    Trace Commenting fields...;
    Comment Field [currency_rate_id] With 'Primary key for CurrencyRate records.';
    Comment Field [average_rate] With 'Average exchange rate for the day.';
    Comment Field [currency_rate_date] With 'Date and time the exchange rate was obtained.';
    Comment Field [end_of_day_rate] With 'Final exchange rate for the day.';
    Comment Field [from_currency_code] With 'Exchange rate was converted from this currency code.';
    Comment Field [to_currency_code] With 'Exchange rate was converted to this currency code.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__currency_rates] Into [$(val__qvd_path__das)/raw__adventure_works__currency_rates.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__currency_rates];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__customers
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__customers.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [customer_id],
    [person_id],
    [store_id],
    [territory_id],
    [account_number],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__customers]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([customer_id]) As [customer_id],
    Text([person_id]) As [person_id],
    Text([store_id]) As [store_id],
    Text([territory_id]) As [territory_id],
    Text([account_number]) As [account_number],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__customers.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__customers'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__customers])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__customers] With 'Current customer information. Also see the Person and Store tables.';

    Trace Commenting fields...;
    Comment Field [customer_id] With 'Primary key.';
    Comment Field [person_id] With 'Foreign key to Person.BusinessEntityID.';
    Comment Field [store_id] With 'Foreign key to Store.BusinessEntityID.';
    Comment Field [territory_id] With 'ID of the territory in which the customer is located. Foreign key to SalesTerritory.SalesTerritoryID.';
    Comment Field [account_number] With 'Unique number identifying the customer assigned by the accounting system.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__customers] Into [$(val__qvd_path__das)/raw__adventure_works__customers.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__customers];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__departments
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__departments.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [department_id],
    [group_name],
    [name],
    [modified_date]
)
;

[raw__adventure_works__departments]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([department_id]) As [department_id],
    Text([group_name]) As [group_name],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__departments.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__departments'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__departments])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__departments] With 'Lookup table containing the departments within the Adventure Works Cycles company.';

    Trace Commenting fields...;
    Comment Field [department_id] With 'Primary key for Department records.';
    Comment Field [group_name] With 'Name of the group to which the department belongs.';
    Comment Field [name] With 'Name of the department.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__departments] Into [$(val__qvd_path__das)/raw__adventure_works__departments.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__departments];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__email_addresses
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__email_addresses.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [email_address_id],
    [email],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__email_addresses]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([email_address_id]) As [email_address_id],
    Text([email]) As [email],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__email_addresses.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__email_addresses'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__email_addresses])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__email_addresses] With 'Where to send a person email.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key. Person associated with this email address. Foreign key to Person.BusinessEntityID.';
    Comment Field [email_address_id] With 'Primary key. ID of this email address.';
    Comment Field [email] With 'E-mail address for the person.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__email_addresses] Into [$(val__qvd_path__das)/raw__adventure_works__email_addresses.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__email_addresses];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__employee_department_histories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__employee_department_histories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [department_id],
    [shift_id],
    [end_date],
    [start_date],
    [modified_date]
)
;

[raw__adventure_works__employee_department_histories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([department_id]) As [department_id],
    Text([shift_id]) As [shift_id],
    Text([end_date]) As [end_date],
    Text([start_date]) As [start_date],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__employee_department_histories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__employee_department_histories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__employee_department_histories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__employee_department_histories] With 'Employee department transfers.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Employee identification number. Foreign key to Employee.BusinessEntityID.';
    Comment Field [department_id] With 'Department in which the employee worked including currently. Foreign key to Department.DepartmentID.';
    Comment Field [shift_id] With 'Identifies which 8-hour shift the employee works. Foreign key to Shift.Shift.ID.';
    Comment Field [end_date] With 'Date the employee left the department. NULL = Current department.';
    Comment Field [start_date] With 'Date the employee started work in the department.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__employee_department_histories] Into [$(val__qvd_path__das)/raw__adventure_works__employee_department_histories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__employee_department_histories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__employee_pay_histories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__employee_pay_histories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [pay_frequency],
    [rate],
    [rate_change_date],
    [modified_date]
)
;

[raw__adventure_works__employee_pay_histories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([pay_frequency]) As [pay_frequency],
    Text([rate]) As [rate],
    Text([rate_change_date]) As [rate_change_date],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__employee_pay_histories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__employee_pay_histories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__employee_pay_histories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__employee_pay_histories] With 'Employee pay history.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Employee identification number. Foreign key to Employee.BusinessEntityID.';
    Comment Field [pay_frequency] With '1 = Salary received monthly, 2 = Salary received biweekly.';
    Comment Field [rate] With 'Salary hourly rate.';
    Comment Field [rate_change_date] With 'Date the change in pay is effective.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__employee_pay_histories] Into [$(val__qvd_path__das)/raw__adventure_works__employee_pay_histories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__employee_pay_histories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__employees
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__employees.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [login_id],
    [birth_date],
    [current_flag],
    [gender],
    [hire_date],
    [job_title],
    [marital_status],
    [national_idnumber],
    [organization_level],
    [salaried_flag],
    [sick_leave_hours],
    [vacation_hours],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__employees]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([login_id]) As [login_id],
    Text([birth_date]) As [birth_date],
    Text([current_flag]) As [current_flag],
    Text([gender]) As [gender],
    Text([hire_date]) As [hire_date],
    Text([job_title]) As [job_title],
    Text([marital_status]) As [marital_status],
    Text([national_idnumber]) As [national_idnumber],
    Text([organization_level]) As [organization_level],
    Text([salaried_flag]) As [salaried_flag],
    Text([sick_leave_hours]) As [sick_leave_hours],
    Text([vacation_hours]) As [vacation_hours],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__employees.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__employees'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__employees])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__employees] With 'Employee information.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key for Employee records. Foreign key to BusinessEntity.BusinessEntityID.';
    Comment Field [login_id] With 'Network login.';
    Comment Field [birth_date] With 'Date of birth.';
    Comment Field [current_flag] With '0 = Inactive, 1 = Active.';
    Comment Field [gender] With 'M = Male, F = Female.';
    Comment Field [hire_date] With 'Employee hired on this date.';
    Comment Field [job_title] With 'Work title such as Buyer or Sales Representative.';
    Comment Field [marital_status] With 'M = Married, S = Single.';
    Comment Field [national_idnumber] With 'Unique national identification number such as a social security number.';
    Comment Field [organization_level] With 'The depth of the employee in the corporate hierarchy.';
    Comment Field [salaried_flag] With 'Job classification. 0 = Hourly, not exempt from collective bargaining. 1 = Salaried, exempt from collective bargaining.';
    Comment Field [sick_leave_hours] With 'Number of available sick leave hours.';
    Comment Field [vacation_hours] With 'Number of available vacation hours.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__employees] Into [$(val__qvd_path__das)/raw__adventure_works__employees.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__employees];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__illustrations
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__illustrations.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [illustration_id],
    [diagram],
    [modified_date]
)
;

[raw__adventure_works__illustrations]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([illustration_id]) As [illustration_id],
    Text([diagram]) As [diagram],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__illustrations.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__illustrations'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__illustrations])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__illustrations] With 'Bicycle assembly diagrams.';

    Trace Commenting fields...;
    Comment Field [illustration_id] With 'Primary key for Illustration records.';
    Comment Field [diagram] With 'Illustrations used in manufacturing instructions. Stored as XML.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__illustrations] Into [$(val__qvd_path__das)/raw__adventure_works__illustrations.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__illustrations];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__job_candidates
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__job_candidates.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [job_candidate_id],
    [resume],
    [modified_date]
)
;

[raw__adventure_works__job_candidates]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([job_candidate_id]) As [job_candidate_id],
    Text([resume]) As [resume],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__job_candidates.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__job_candidates'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__job_candidates])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__job_candidates] With 'Rsums submitted to Human Resources by job applicants.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Employee identification number if applicant was hired. Foreign key to Employee.BusinessEntityID.';
    Comment Field [job_candidate_id] With 'Primary key for JobCandidate records.';
    Comment Field [resume] With 'Rsum in XML format.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__job_candidates] Into [$(val__qvd_path__das)/raw__adventure_works__job_candidates.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__job_candidates];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__locations
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__locations.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [location_id],
    [availability],
    [cost_rate],
    [name],
    [modified_date]
)
;

[raw__adventure_works__locations]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([location_id]) As [location_id],
    Text([availability]) As [availability],
    Text([cost_rate]) As [cost_rate],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__locations.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__locations'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__locations])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__locations] With 'Product inventory and manufacturing locations.';

    Trace Commenting fields...;
    Comment Field [location_id] With 'Primary key for Location records.';
    Comment Field [availability] With 'Work capacity (in hours) of the manufacturing location.';
    Comment Field [cost_rate] With 'Standard hourly cost of the manufacturing location.';
    Comment Field [name] With 'Location description.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__locations] Into [$(val__qvd_path__das)/raw__adventure_works__locations.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__locations];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__person_phones
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__person_phones.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [phone_number_type_id],
    [phone_number],
    [modified_date]
)
;

[raw__adventure_works__person_phones]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([phone_number_type_id]) As [phone_number_type_id],
    Text([phone_number]) As [phone_number],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__person_phones.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__person_phones'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__person_phones])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__person_phones] With 'Telephone number and type of a person.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Business entity identification number. Foreign key to Person.BusinessEntityID.';
    Comment Field [phone_number_type_id] With 'Kind of phone number. Foreign key to PhoneNumberType.PhoneNumberTypeID.';
    Comment Field [phone_number] With 'Telephone number identification number.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__person_phones] Into [$(val__qvd_path__das)/raw__adventure_works__person_phones.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__person_phones];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__persons
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__persons.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [additional_contact_info],
    [demographics],
    [email_promotion],
    [first_name],
    [last_name],
    [middle_name],
    [name_style],
    [person_type],
    [suffix],
    [title],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__persons]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([additional_contact_info]) As [additional_contact_info],
    Text([demographics]) As [demographics],
    Text([email_promotion]) As [email_promotion],
    Text([first_name]) As [first_name],
    Text([last_name]) As [last_name],
    Text([middle_name]) As [middle_name],
    Text([name_style]) As [name_style],
    Text([person_type]) As [person_type],
    Text([suffix]) As [suffix],
    Text([title]) As [title],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__persons.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__persons'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__persons])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__persons] With 'Human beings involved with AdventureWorks: employees, customer contacts, and vendor contacts.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key for Person records.';
    Comment Field [additional_contact_info] With 'Additional contact information about the person stored in xml format.';
    Comment Field [demographics] With 'Personal information such as hobbies, and income collected from online shoppers. Used for sales analysis.';
    Comment Field [email_promotion] With '0 = Contact does not wish to receive e-mail promotions, 1 = Contact does wish to receive e-mail promotions from AdventureWorks, 2 = Contact does wish to receive e-mail promotions from AdventureWorks and selected partners.';
    Comment Field [first_name] With 'First name of the person.';
    Comment Field [last_name] With 'Last name of the person.';
    Comment Field [middle_name] With 'Middle name or middle initial of the person.';
    Comment Field [name_style] With '0 = The data in FirstName and LastName are stored in western style (first name, last name) order. 1 = Eastern style (last name, first name) order.';
    Comment Field [person_type] With 'Primary type of person: SC = Store Contact, IN = Individual (retail) customer, SP = Sales person, EM = Employee (non-sales), VC = Vendor contact, GC = General contact.';
    Comment Field [suffix] With 'Surname suffix. For example, Sr. or Jr.';
    Comment Field [title] With 'A courtesy title. For example, Mr. or Ms.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__persons] Into [$(val__qvd_path__das)/raw__adventure_works__persons.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__persons];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__phone_number_types
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__phone_number_types.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [phone_number_type_id],
    [name],
    [modified_date]
)
;

[raw__adventure_works__phone_number_types]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([phone_number_type_id]) As [phone_number_type_id],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__phone_number_types.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__phone_number_types'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__phone_number_types])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__phone_number_types] With 'Type of phone number of a person.';

    Trace Commenting fields...;
    Comment Field [phone_number_type_id] With 'Primary key for telephone number type records.';
    Comment Field [name] With 'Name of the telephone number type.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__phone_number_types] Into [$(val__qvd_path__das)/raw__adventure_works__phone_number_types.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__phone_number_types];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_categories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_categories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_category_id],
    [name],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__product_categories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_category_id]) As [product_category_id],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_categories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_categories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_categories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_categories] With 'High-level product categorization.';

    Trace Commenting fields...;
    Comment Field [product_category_id] With 'Primary key for ProductCategory records.';
    Comment Field [name] With 'Category description.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__product_categories] Into [$(val__qvd_path__das)/raw__adventure_works__product_categories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_categories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_cost_histories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_cost_histories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [end_date],
    [standard_cost],
    [start_date],
    [modified_date]
)
;

[raw__adventure_works__product_cost_histories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([end_date]) As [end_date],
    Text([standard_cost]) As [standard_cost],
    Text([start_date]) As [start_date],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_cost_histories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_cost_histories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_cost_histories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_cost_histories] With 'Changes in the cost of a product over time.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [end_date] With 'Product cost end date.';
    Comment Field [standard_cost] With 'Standard cost of the product.';
    Comment Field [start_date] With 'Product cost start date.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__product_cost_histories] Into [$(val__qvd_path__das)/raw__adventure_works__product_cost_histories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_cost_histories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_descriptions
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_descriptions.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_description_id],
    [description],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__product_descriptions]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_description_id]) As [product_description_id],
    Text([description]) As [description],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_descriptions.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_descriptions'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_descriptions])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_descriptions] With 'Product descriptions in several languages.';

    Trace Commenting fields...;
    Comment Field [product_description_id] With 'Primary key for ProductDescription records.';
    Comment Field [description] With 'Description of the product.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__product_descriptions] Into [$(val__qvd_path__das)/raw__adventure_works__product_descriptions.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_descriptions];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_inventories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_inventories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [location_id],
    [product_id],
    [bin],
    [quantity],
    [shelf],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__product_inventories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([location_id]) As [location_id],
    Text([product_id]) As [product_id],
    Text([bin]) As [bin],
    Text([quantity]) As [quantity],
    Text([shelf]) As [shelf],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_inventories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_inventories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_inventories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_inventories] With 'Product inventory information.';

    Trace Commenting fields...;
    Comment Field [location_id] With 'Inventory location identification number. Foreign key to Location.LocationID.';
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [bin] With 'Storage container on a shelf in an inventory location.';
    Comment Field [quantity] With 'Quantity of products in the inventory location.';
    Comment Field [shelf] With 'Storage compartment within an inventory location.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__product_inventories] Into [$(val__qvd_path__das)/raw__adventure_works__product_inventories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_inventories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_list_price_histories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_list_price_histories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [end_date],
    [list_price],
    [start_date],
    [modified_date]
)
;

[raw__adventure_works__product_list_price_histories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([end_date]) As [end_date],
    Text([list_price]) As [list_price],
    Text([start_date]) As [start_date],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_list_price_histories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_list_price_histories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_list_price_histories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_list_price_histories] With 'Changes in the list price of a product over time.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [end_date] With 'List price end date.';
    Comment Field [list_price] With 'Product list price.';
    Comment Field [start_date] With 'List price start date.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__product_list_price_histories] Into [$(val__qvd_path__das)/raw__adventure_works__product_list_price_histories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_list_price_histories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_model_illustrations
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_model_illustrations.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [illustration_id],
    [product_model_id],
    [modified_date]
)
;

[raw__adventure_works__product_model_illustrations]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([illustration_id]) As [illustration_id],
    Text([product_model_id]) As [product_model_id],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_model_illustrations.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_model_illustrations'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_model_illustrations])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_model_illustrations] With 'Cross-reference table mapping product models and illustrations.';

    Trace Commenting fields...;
    Comment Field [illustration_id] With 'Primary key. Foreign key to Illustration.IllustrationID.';
    Comment Field [product_model_id] With 'Primary key. Foreign key to ProductModel.ProductModelID.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__product_model_illustrations] Into [$(val__qvd_path__das)/raw__adventure_works__product_model_illustrations.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_model_illustrations];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_models
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_models.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_model_id],
    [catalog_description],
    [instructions],
    [name],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__product_models]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_model_id]) As [product_model_id],
    Text([catalog_description]) As [catalog_description],
    Text([instructions]) As [instructions],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_models.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_models'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_models])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_models] With 'Product model classification.';

    Trace Commenting fields...;
    Comment Field [product_model_id] With 'Primary key for ProductModel records.';
    Comment Field [catalog_description] With 'Detailed product catalog information in xml format.';
    Comment Field [instructions] With 'Manufacturing instructions in xml format.';
    Comment Field [name] With 'Product model description.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__product_models] Into [$(val__qvd_path__das)/raw__adventure_works__product_models.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_models];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_photos
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_photos.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_photo_id],
    [large_photo],
    [large_photo_file_name],
    [thumb_nail_photo],
    [thumbnail_photo_file_name],
    [modified_date]
)
;

[raw__adventure_works__product_photos]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_photo_id]) As [product_photo_id],
    Text([large_photo]) As [large_photo],
    Text([large_photo_file_name]) As [large_photo_file_name],
    Text([thumb_nail_photo]) As [thumb_nail_photo],
    Text([thumbnail_photo_file_name]) As [thumbnail_photo_file_name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_photos.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_photos'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_photos])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_photos] With 'Product images.';

    Trace Commenting fields...;
    Comment Field [product_photo_id] With 'Primary key for ProductPhoto records.';
    Comment Field [large_photo] With 'Large image of the product.';
    Comment Field [large_photo_file_name] With 'Large image file name.';
    Comment Field [thumb_nail_photo] With 'Small image of the product.';
    Comment Field [thumbnail_photo_file_name] With 'Small image file name.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__product_photos] Into [$(val__qvd_path__das)/raw__adventure_works__product_photos.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_photos];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_reviews
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_reviews.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [product_review_id],
    [comments],
    [email_address],
    [rating],
    [review_date],
    [reviewer_name],
    [modified_date]
)
;

[raw__adventure_works__product_reviews]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([product_review_id]) As [product_review_id],
    Text([comments]) As [comments],
    Text([email_address]) As [email_address],
    Text([rating]) As [rating],
    Text([review_date]) As [review_date],
    Text([reviewer_name]) As [reviewer_name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_reviews.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_reviews'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_reviews])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_reviews] With 'Customer reviews of products they have purchased.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [product_review_id] With 'Primary key for ProductReview records.';
    Comment Field [comments] With 'Reviewer$(=Chr39())s comments.';
    Comment Field [email_address] With 'Reviewer$(=Chr39())s e-mail address.';
    Comment Field [rating] With 'Product rating given by the reviewer. Scale is 1 to 5 with 5 as the highest rating.';
    Comment Field [review_date] With 'Date review was submitted.';
    Comment Field [reviewer_name] With 'Name of the reviewer.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__product_reviews] Into [$(val__qvd_path__das)/raw__adventure_works__product_reviews.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_reviews];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__products
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__products.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [product_model_id],
    [product_subcategory_id],
    [class],
    [color],
    [days_to_manufacture],
    [finished_goods_flag],
    [list_price],
    [make_flag],
    [name],
    [product_line],
    [product_number],
    [reorder_point],
    [safety_stock_level],
    [sell_end_date],
    [sell_start_date],
    [size],
    [size_unit_measure_code],
    [standard_cost],
    [style],
    [weight],
    [weight_unit_measure_code],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__products]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([product_model_id]) As [product_model_id],
    Text([product_subcategory_id]) As [product_subcategory_id],
    Text([class]) As [class],
    Text([color]) As [color],
    Text([days_to_manufacture]) As [days_to_manufacture],
    Text([finished_goods_flag]) As [finished_goods_flag],
    Text([list_price]) As [list_price],
    Text([make_flag]) As [make_flag],
    Text([name]) As [name],
    Text([product_line]) As [product_line],
    Text([product_number]) As [product_number],
    Text([reorder_point]) As [reorder_point],
    Text([safety_stock_level]) As [safety_stock_level],
    Text([sell_end_date]) As [sell_end_date],
    Text([sell_start_date]) As [sell_start_date],
    Text([size]) As [size],
    Text([size_unit_measure_code]) As [size_unit_measure_code],
    Text([standard_cost]) As [standard_cost],
    Text([style]) As [style],
    Text([weight]) As [weight],
    Text([weight_unit_measure_code]) As [weight_unit_measure_code],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__products.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__products'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__products])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__products] With 'Products sold or used in the manufacturing of sold products.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Primary key for Product records.';
    Comment Field [product_model_id] With 'Product is a member of this product model. Foreign key to ProductModel.ProductModelID.';
    Comment Field [product_subcategory_id] With 'Product is a member of this product subcategory. Foreign key to ProductSubCategory.ProductSubCategoryID.';
    Comment Field [class] With 'H = High, M = Medium, L = Low.';
    Comment Field [color] With 'Product color.';
    Comment Field [days_to_manufacture] With 'Number of days required to manufacture the product.';
    Comment Field [finished_goods_flag] With '0 = Product is not a salable item. 1 = Product is salable.';
    Comment Field [list_price] With 'Selling price.';
    Comment Field [make_flag] With '0 = Product is purchased, 1 = Product is manufactured in-house.';
    Comment Field [name] With 'Name of the product.';
    Comment Field [product_line] With 'R = Road, M = Mountain, T = Touring, S = Standard.';
    Comment Field [product_number] With 'Unique product identification number.';
    Comment Field [reorder_point] With 'Inventory level that triggers a purchase order or work order.';
    Comment Field [safety_stock_level] With 'Minimum inventory quantity.';
    Comment Field [sell_end_date] With 'Date the product was no longer available for sale.';
    Comment Field [sell_start_date] With 'Date the product was available for sale.';
    Comment Field [size] With 'Product size.';
    Comment Field [size_unit_measure_code] With 'Unit of measure for Size column.';
    Comment Field [standard_cost] With 'Standard cost of the product.';
    Comment Field [style] With 'W = Womens, M = Mens, U = Universal.';
    Comment Field [weight] With 'Product weight.';
    Comment Field [weight_unit_measure_code] With 'Unit of measure for Weight column.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__products] Into [$(val__qvd_path__das)/raw__adventure_works__products.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__products];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_subcategories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_subcategories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_category_id],
    [product_subcategory_id],
    [name],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__product_subcategories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_category_id]) As [product_category_id],
    Text([product_subcategory_id]) As [product_subcategory_id],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_subcategories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_subcategories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_subcategories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_subcategories] With 'Product subcategories. See ProductCategory table.';

    Trace Commenting fields...;
    Comment Field [product_category_id] With 'Product category identification number. Foreign key to ProductCategory.ProductCategoryID.';
    Comment Field [product_subcategory_id] With 'Primary key for ProductSubcategory records.';
    Comment Field [name] With 'Subcategory description.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__product_subcategories] Into [$(val__qvd_path__das)/raw__adventure_works__product_subcategories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_subcategories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__product_vendors
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__product_vendors.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [product_id],
    [average_lead_time],
    [last_receipt_cost],
    [last_receipt_date],
    [max_order_qty],
    [min_order_qty],
    [on_order_qty],
    [standard_price],
    [unit_measure_code],
    [modified_date]
)
;

[raw__adventure_works__product_vendors]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([product_id]) As [product_id],
    Text([average_lead_time]) As [average_lead_time],
    Text([last_receipt_cost]) As [last_receipt_cost],
    Text([last_receipt_date]) As [last_receipt_date],
    Text([max_order_qty]) As [max_order_qty],
    Text([min_order_qty]) As [min_order_qty],
    Text([on_order_qty]) As [on_order_qty],
    Text([standard_price]) As [standard_price],
    Text([unit_measure_code]) As [unit_measure_code],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__product_vendors.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__product_vendors'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__product_vendors])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__product_vendors] With 'Cross-reference table mapping vendors with the products they supply.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key. Foreign key to Vendor.BusinessEntityID.';
    Comment Field [product_id] With 'Primary key. Foreign key to Product.ProductID.';
    Comment Field [average_lead_time] With 'The average span of time (in days) between placing an order with the vendor and receiving the purchased product.';
    Comment Field [last_receipt_cost] With 'The selling price when last purchased.';
    Comment Field [last_receipt_date] With 'Date the product was last received by the vendor.';
    Comment Field [max_order_qty] With 'The maximum quantity that should be ordered.';
    Comment Field [min_order_qty] With 'The minimum quantity that should be ordered.';
    Comment Field [on_order_qty] With 'The quantity currently on order.';
    Comment Field [standard_price] With 'The vendor$(=Chr39())s usual selling price.';
    Comment Field [unit_measure_code] With 'The product$(=Chr39())s unit of measure.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__product_vendors] Into [$(val__qvd_path__das)/raw__adventure_works__product_vendors.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__product_vendors];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__purchase_order_details
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__purchase_order_details.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [purchase_order_detail_id],
    [purchase_order_id],
    [due_date],
    [line_total],
    [order_qty],
    [received_qty],
    [rejected_qty],
    [stocked_qty],
    [unit_price],
    [modified_date]
)
;

[raw__adventure_works__purchase_order_details]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([purchase_order_detail_id]) As [purchase_order_detail_id],
    Text([purchase_order_id]) As [purchase_order_id],
    Text([due_date]) As [due_date],
    Text([line_total]) As [line_total],
    Text([order_qty]) As [order_qty],
    Text([received_qty]) As [received_qty],
    Text([rejected_qty]) As [rejected_qty],
    Text([stocked_qty]) As [stocked_qty],
    Text([unit_price]) As [unit_price],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__purchase_order_details.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__purchase_order_details'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__purchase_order_details])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__purchase_order_details] With 'Individual products associated with a specific purchase order. See PurchaseOrderHeader.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [purchase_order_detail_id] With 'Primary key. One line number per purchased product.';
    Comment Field [purchase_order_id] With 'Primary key. Foreign key to PurchaseOrderHeader.PurchaseOrderID.';
    Comment Field [due_date] With 'Date the product is expected to be received.';
    Comment Field [line_total] With 'Per product subtotal. Computed as OrderQty * UnitPrice.';
    Comment Field [order_qty] With 'Quantity ordered.';
    Comment Field [received_qty] With 'Quantity actually received from the vendor.';
    Comment Field [rejected_qty] With 'Quantity rejected during inspection.';
    Comment Field [stocked_qty] With 'Quantity accepted into inventory. Computed as ReceivedQty - RejectedQty.';
    Comment Field [unit_price] With 'Vendor$(=Chr39())s selling price of a single product.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__purchase_order_details] Into [$(val__qvd_path__das)/raw__adventure_works__purchase_order_details.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__purchase_order_details];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__purchase_order_headers
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__purchase_order_headers.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [employee_id],
    [purchase_order_id],
    [ship_method_id],
    [vendor_id],
    [freight],
    [order_date],
    [revision_number],
    [ship_date],
    [status],
    [sub_total],
    [tax_amt],
    [total_due],
    [modified_date]
)
;

[raw__adventure_works__purchase_order_headers]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([employee_id]) As [employee_id],
    Text([purchase_order_id]) As [purchase_order_id],
    Text([ship_method_id]) As [ship_method_id],
    Text([vendor_id]) As [vendor_id],
    Text([freight]) As [freight],
    Text([order_date]) As [order_date],
    Text([revision_number]) As [revision_number],
    Text([ship_date]) As [ship_date],
    Text([status]) As [status],
    Text([sub_total]) As [sub_total],
    Text([tax_amt]) As [tax_amt],
    Text([total_due]) As [total_due],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__purchase_order_headers.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__purchase_order_headers'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__purchase_order_headers])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__purchase_order_headers] With 'General purchase order information. See PurchaseOrderDetail.';

    Trace Commenting fields...;
    Comment Field [employee_id] With 'Employee who created the purchase order. Foreign key to Employee.BusinessEntityID.';
    Comment Field [purchase_order_id] With 'Primary key.';
    Comment Field [ship_method_id] With 'Shipping method. Foreign key to ShipMethod.ShipMethodID.';
    Comment Field [vendor_id] With 'Vendor with whom the purchase order is placed. Foreign key to Vendor.BusinessEntityID.';
    Comment Field [freight] With 'Shipping cost.';
    Comment Field [order_date] With 'Purchase order creation date.';
    Comment Field [revision_number] With 'Incremental number to track changes to the purchase order over time.';
    Comment Field [ship_date] With 'Estimated shipment date from the vendor.';
    Comment Field [status] With 'Order current status. 1 = Pending; 2 = Approved; 3 = Rejected; 4 = Complete.';
    Comment Field [sub_total] With 'Purchase order subtotal. Computed as SUM(PurchaseOrderDetail.LineTotal) for the appropriate PurchaseOrderID.';
    Comment Field [tax_amt] With 'Tax amount.';
    Comment Field [total_due] With 'Total due to vendor. Computed as Subtotal + TaxAmt + Freight.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__purchase_order_headers] Into [$(val__qvd_path__das)/raw__adventure_works__purchase_order_headers.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__purchase_order_headers];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_order_details
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_order_details.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [sales_order_detail_id],
    [sales_order_id],
    [special_offer_id],
    [carrier_tracking_number],
    [line_total],
    [order_qty],
    [unit_price],
    [unit_price_discount],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__sales_order_details]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([sales_order_detail_id]) As [sales_order_detail_id],
    Text([sales_order_id]) As [sales_order_id],
    Text([special_offer_id]) As [special_offer_id],
    Text([carrier_tracking_number]) As [carrier_tracking_number],
    Text([line_total]) As [line_total],
    Text([order_qty]) As [order_qty],
    Text([unit_price]) As [unit_price],
    Text([unit_price_discount]) As [unit_price_discount],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_order_details.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_order_details'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_order_details])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_order_details] With 'Individual products associated with a specific sales order. See SalesOrderHeader.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product sold to customer. Foreign key to Product.ProductID.';
    Comment Field [sales_order_detail_id] With 'Primary key. One incremental unique number per product sold.';
    Comment Field [sales_order_id] With 'Primary key. Foreign key to SalesOrderHeader.SalesOrderID.';
    Comment Field [special_offer_id] With 'Promotional code. Foreign key to SpecialOffer.SpecialOfferID.';
    Comment Field [carrier_tracking_number] With 'Shipment tracking number supplied by the shipper.';
    Comment Field [line_total] With 'Per product subtotal. Computed as UnitPrice * (1 - UnitPriceDiscount) * OrderQty.';
    Comment Field [order_qty] With 'Quantity ordered per product.';
    Comment Field [unit_price] With 'Selling price of a single product.';
    Comment Field [unit_price_discount] With 'Discount amount.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_order_details] Into [$(val__qvd_path__das)/raw__adventure_works__sales_order_details.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_order_details];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_order_headers
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_order_headers.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [bill_to_address_id],
    [credit_card_id],
    [currency_rate_id],
    [customer_id],
    [sales_order_id],
    [sales_person_id],
    [ship_method_id],
    [ship_to_address_id],
    [territory_id],
    [account_number],
    [credit_card_approval_code],
    [due_date],
    [freight],
    [online_order_flag],
    [order_date],
    [purchase_order_number],
    [revision_number],
    [sales_order_number],
    [ship_date],
    [status],
    [sub_total],
    [tax_amt],
    [total_due],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__sales_order_headers]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([bill_to_address_id]) As [bill_to_address_id],
    Text([credit_card_id]) As [credit_card_id],
    Text([currency_rate_id]) As [currency_rate_id],
    Text([customer_id]) As [customer_id],
    Text([sales_order_id]) As [sales_order_id],
    Text([sales_person_id]) As [sales_person_id],
    Text([ship_method_id]) As [ship_method_id],
    Text([ship_to_address_id]) As [ship_to_address_id],
    Text([territory_id]) As [territory_id],
    Text([account_number]) As [account_number],
    Text([credit_card_approval_code]) As [credit_card_approval_code],
    Text([due_date]) As [due_date],
    Text([freight]) As [freight],
    Text([online_order_flag]) As [online_order_flag],
    Text([order_date]) As [order_date],
    Text([purchase_order_number]) As [purchase_order_number],
    Text([revision_number]) As [revision_number],
    Text([sales_order_number]) As [sales_order_number],
    Text([ship_date]) As [ship_date],
    Text([status]) As [status],
    Text([sub_total]) As [sub_total],
    Text([tax_amt]) As [tax_amt],
    Text([total_due]) As [total_due],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_order_headers.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_order_headers'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_order_headers])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_order_headers] With 'General sales order information.';

    Trace Commenting fields...;
    Comment Field [bill_to_address_id] With 'Customer billing address. Foreign key to Address.AddressID.';
    Comment Field [credit_card_id] With 'Credit card identification number. Foreign key to CreditCard.CreditCardID.';
    Comment Field [currency_rate_id] With 'Currency exchange rate used. Foreign key to CurrencyRate.CurrencyRateID.';
    Comment Field [customer_id] With 'Customer identification number. Foreign key to Customer.BusinessEntityID.';
    Comment Field [sales_order_id] With 'Primary key.';
    Comment Field [sales_person_id] With 'Sales person who created the sales order. Foreign key to SalesPerson.BusinessEntityID.';
    Comment Field [ship_method_id] With 'Shipping method. Foreign key to ShipMethod.ShipMethodID.';
    Comment Field [ship_to_address_id] With 'Customer shipping address. Foreign key to Address.AddressID.';
    Comment Field [territory_id] With 'Territory in which the sale was made. Foreign key to SalesTerritory.SalesTerritoryID.';
    Comment Field [account_number] With 'Financial accounting number reference.';
    Comment Field [credit_card_approval_code] With 'Approval code provided by the credit card company.';
    Comment Field [due_date] With 'Date the order is due to the customer.';
    Comment Field [freight] With 'Shipping cost.';
    Comment Field [online_order_flag] With '0 = Order placed by sales person. 1 = Order placed online by customer.';
    Comment Field [order_date] With 'Dates the sales order was created.';
    Comment Field [purchase_order_number] With 'Customer purchase order number reference.';
    Comment Field [revision_number] With 'Incremental number to track changes to the sales order over time.';
    Comment Field [sales_order_number] With 'Unique sales order identification number.';
    Comment Field [ship_date] With 'Date the order was shipped to the customer.';
    Comment Field [status] With 'Order current status. 1 = In process; 2 = Approved; 3 = Backordered; 4 = Rejected; 5 = Shipped; 6 = Cancelled.';
    Comment Field [sub_total] With 'Sales subtotal. Computed as SUM(SalesOrderDetail.LineTotal) for the appropriate SalesOrderID.';
    Comment Field [tax_amt] With 'Tax amount.';
    Comment Field [total_due] With 'Total due from customer. Computed as Subtotal + TaxAmt + Freight.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_order_headers] Into [$(val__qvd_path__das)/raw__adventure_works__sales_order_headers.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_order_headers];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_person_quota_histories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_person_quota_histories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [quota_date],
    [sales_quota],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__sales_person_quota_histories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([quota_date]) As [quota_date],
    Text([sales_quota]) As [sales_quota],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_person_quota_histories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_person_quota_histories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_person_quota_histories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_person_quota_histories] With 'Sales performance tracking.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Sales person identification number. Foreign key to SalesPerson.BusinessEntityID.';
    Comment Field [quota_date] With 'Sales quota date.';
    Comment Field [sales_quota] With 'Sales quota amount.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_person_quota_histories] Into [$(val__qvd_path__das)/raw__adventure_works__sales_person_quota_histories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_person_quota_histories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_persons
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_persons.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [territory_id],
    [bonus],
    [commission_pct],
    [sales_last_year],
    [sales_quota],
    [sales_ytd],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__sales_persons]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([territory_id]) As [territory_id],
    Text([bonus]) As [bonus],
    Text([commission_pct]) As [commission_pct],
    Text([sales_last_year]) As [sales_last_year],
    Text([sales_quota]) As [sales_quota],
    Text([sales_ytd]) As [sales_ytd],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_persons.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_persons'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_persons])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_persons] With 'Sales representative current information.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key for SalesPerson records. Foreign key to Employee.BusinessEntityID.';
    Comment Field [territory_id] With 'Territory currently assigned to. Foreign key to SalesTerritory.SalesTerritoryID.';
    Comment Field [bonus] With 'Bonus due if quota is met.';
    Comment Field [commission_pct] With 'Commission percent received per sale.';
    Comment Field [sales_last_year] With 'Sales total of previous year.';
    Comment Field [sales_quota] With 'Projected yearly sales.';
    Comment Field [sales_ytd] With 'Sales total year to date.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_persons] Into [$(val__qvd_path__das)/raw__adventure_works__sales_persons.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_persons];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_reasons
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_reasons.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [sales_reason_id],
    [name],
    [reason_type],
    [modified_date]
)
;

[raw__adventure_works__sales_reasons]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([sales_reason_id]) As [sales_reason_id],
    Text([name]) As [name],
    Text([reason_type]) As [reason_type],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_reasons.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_reasons'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_reasons])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_reasons] With 'Lookup table of customer purchase reasons.';

    Trace Commenting fields...;
    Comment Field [sales_reason_id] With 'Primary key for SalesReason records.';
    Comment Field [name] With 'Sales reason description.';
    Comment Field [reason_type] With 'Category the sales reason belongs to.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_reasons] Into [$(val__qvd_path__das)/raw__adventure_works__sales_reasons.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_reasons];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_tax_rates
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_tax_rates.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [sales_tax_rate_id],
    [state_province_id],
    [name],
    [tax_rate],
    [tax_type],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__sales_tax_rates]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([sales_tax_rate_id]) As [sales_tax_rate_id],
    Text([state_province_id]) As [state_province_id],
    Text([name]) As [name],
    Text([tax_rate]) As [tax_rate],
    Text([tax_type]) As [tax_type],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_tax_rates.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_tax_rates'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_tax_rates])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_tax_rates] With 'Tax rate lookup table.';

    Trace Commenting fields...;
    Comment Field [sales_tax_rate_id] With 'Primary key for SalesTaxRate records.';
    Comment Field [state_province_id] With 'State, province, or country/region the sales tax applies to.';
    Comment Field [name] With 'Tax rate description.';
    Comment Field [tax_rate] With 'Tax rate amount.';
    Comment Field [tax_type] With '1 = Tax applied to retail transactions, 2 = Tax applied to wholesale transactions, 3 = Tax applied to all sales (retail and wholesale) transactions.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_tax_rates] Into [$(val__qvd_path__das)/raw__adventure_works__sales_tax_rates.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_tax_rates];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_territories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_territories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [territory_id],
    [cost_last_year],
    [cost_ytd],
    [country_region_code],
    [group],
    [name],
    [sales_last_year],
    [sales_ytd],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__sales_territories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([territory_id]) As [territory_id],
    Text([cost_last_year]) As [cost_last_year],
    Text([cost_ytd]) As [cost_ytd],
    Text([country_region_code]) As [country_region_code],
    Text([group]) As [group],
    Text([name]) As [name],
    Text([sales_last_year]) As [sales_last_year],
    Text([sales_ytd]) As [sales_ytd],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_territories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_territories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_territories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_territories] With 'Sales territory lookup table.';

    Trace Commenting fields...;
    Comment Field [territory_id] With 'Primary key for SalesTerritory records.';
    Comment Field [cost_last_year] With 'Business costs in the territory the previous year.';
    Comment Field [cost_ytd] With 'Business costs in the territory year to date.';
    Comment Field [country_region_code] With 'ISO standard country or region code. Foreign key to CountryRegion.CountryRegionCode.';
    Comment Field [group] With 'Geographic area to which the sales territory belongs.';
    Comment Field [name] With 'Sales territory description.';
    Comment Field [sales_last_year] With 'Sales in the territory the previous year.';
    Comment Field [sales_ytd] With 'Sales in the territory year to date.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_territories] Into [$(val__qvd_path__das)/raw__adventure_works__sales_territories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_territories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__sales_territory_histories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__sales_territory_histories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [territory_id],
    [end_date],
    [start_date],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__sales_territory_histories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([territory_id]) As [territory_id],
    Text([end_date]) As [end_date],
    Text([start_date]) As [start_date],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__sales_territory_histories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__sales_territory_histories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__sales_territory_histories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__sales_territory_histories] With 'Sales representative transfers to other sales territories.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key. The sales rep. Foreign key to SalesPerson.BusinessEntityID.';
    Comment Field [territory_id] With 'Primary key. Territory identification number. Foreign key to SalesTerritory.SalesTerritoryID.';
    Comment Field [end_date] With 'Date the sales representative left work in the territory.';
    Comment Field [start_date] With 'Primary key. Date the sales representative started work in the territory.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__sales_territory_histories] Into [$(val__qvd_path__das)/raw__adventure_works__sales_territory_histories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__sales_territory_histories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__scrap_reasons
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__scrap_reasons.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [scrap_reason_id],
    [name],
    [modified_date]
)
;

[raw__adventure_works__scrap_reasons]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([scrap_reason_id]) As [scrap_reason_id],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__scrap_reasons.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__scrap_reasons'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__scrap_reasons])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__scrap_reasons] With 'Manufacturing failure reasons lookup table.';

    Trace Commenting fields...;
    Comment Field [scrap_reason_id] With 'Primary key for ScrapReason records.';
    Comment Field [name] With 'Failure description.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__scrap_reasons] Into [$(val__qvd_path__das)/raw__adventure_works__scrap_reasons.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__scrap_reasons];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__shifts
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__shifts.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [shift_id],
    [end_time],
    [name],
    [start_time],
    [modified_date]
)
;

[raw__adventure_works__shifts]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([shift_id]) As [shift_id],
    Text([end_time]) As [end_time],
    Text([name]) As [name],
    Text([start_time]) As [start_time],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__shifts.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__shifts'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__shifts])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__shifts] With 'Work shift lookup table.';

    Trace Commenting fields...;
    Comment Field [shift_id] With 'Primary key for Shift records.';
    Comment Field [end_time] With 'Shift end time. ISO duration.';
    Comment Field [name] With 'Shift description.';
    Comment Field [start_time] With 'Shift start time. ISO duration.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__shifts] Into [$(val__qvd_path__das)/raw__adventure_works__shifts.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__shifts];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__ship_methods
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__ship_methods.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [ship_method_id],
    [name],
    [ship_base],
    [ship_rate],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__ship_methods]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([ship_method_id]) As [ship_method_id],
    Text([name]) As [name],
    Text([ship_base]) As [ship_base],
    Text([ship_rate]) As [ship_rate],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__ship_methods.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__ship_methods'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__ship_methods])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__ship_methods] With 'Shipping company lookup table.';

    Trace Commenting fields...;
    Comment Field [ship_method_id] With 'Primary key for ShipMethod records.';
    Comment Field [name] With 'Shipping company name.';
    Comment Field [ship_base] With 'Minimum shipping charge.';
    Comment Field [ship_rate] With 'Shipping charge per pound.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__ship_methods] Into [$(val__qvd_path__das)/raw__adventure_works__ship_methods.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__ship_methods];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__shopping_cart_items
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__shopping_cart_items.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [shopping_cart_id],
    [shopping_cart_item_id],
    [date_created],
    [quantity],
    [modified_date]
)
;

[raw__adventure_works__shopping_cart_items]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([shopping_cart_id]) As [shopping_cart_id],
    Text([shopping_cart_item_id]) As [shopping_cart_item_id],
    Text([date_created]) As [date_created],
    Text([quantity]) As [quantity],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__shopping_cart_items.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__shopping_cart_items'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__shopping_cart_items])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__shopping_cart_items] With 'Contains online customer orders until the order is submitted or cancelled.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product ordered. Foreign key to Product.ProductID.';
    Comment Field [shopping_cart_id] With 'Shopping cart identification number.';
    Comment Field [shopping_cart_item_id] With 'Primary key for ShoppingCartItem records.';
    Comment Field [date_created] With 'Date the time the record was created.';
    Comment Field [quantity] With 'Product quantity ordered.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__shopping_cart_items] Into [$(val__qvd_path__das)/raw__adventure_works__shopping_cart_items.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__shopping_cart_items];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__special_offers
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__special_offers.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [special_offer_id],
    [category],
    [description],
    [discount_percentage],
    [end_date],
    [maximum_quantity],
    [minimum_quantity],
    [start_date],
    [type],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__special_offers]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([special_offer_id]) As [special_offer_id],
    Text([category]) As [category],
    Text([description]) As [description],
    Text([discount_percentage]) As [discount_percentage],
    Text([end_date]) As [end_date],
    Text([maximum_quantity]) As [maximum_quantity],
    Text([minimum_quantity]) As [minimum_quantity],
    Text([start_date]) As [start_date],
    Text([type]) As [type],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__special_offers.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__special_offers'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__special_offers])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__special_offers] With 'Sale discounts lookup table.';

    Trace Commenting fields...;
    Comment Field [special_offer_id] With 'Primary key for SpecialOffer records.';
    Comment Field [category] With 'Group the discount applies to such as Reseller or Customer.';
    Comment Field [description] With 'Discount description.';
    Comment Field [discount_percentage] With 'Discount percentage.';
    Comment Field [end_date] With 'Discount end date.';
    Comment Field [maximum_quantity] With 'Maximum discount percent allowed.';
    Comment Field [minimum_quantity] With 'Minimum discount percent allowed.';
    Comment Field [start_date] With 'Discount start date.';
    Comment Field [type] With 'Discount type category.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__special_offers] Into [$(val__qvd_path__das)/raw__adventure_works__special_offers.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__special_offers];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__state_provinces
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__state_provinces.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [state_province_id],
    [territory_id],
    [country_region_code],
    [is_only_state_province_flag],
    [name],
    [state_province_code],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__state_provinces]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([state_province_id]) As [state_province_id],
    Text([territory_id]) As [territory_id],
    Text([country_region_code]) As [country_region_code],
    Text([is_only_state_province_flag]) As [is_only_state_province_flag],
    Text([name]) As [name],
    Text([state_province_code]) As [state_province_code],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__state_provinces.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__state_provinces'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__state_provinces])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__state_provinces] With 'State and province lookup table.';

    Trace Commenting fields...;
    Comment Field [state_province_id] With 'Primary key for StateProvince records.';
    Comment Field [territory_id] With 'ID of the territory in which the state or province is located. Foreign key to SalesTerritory.SalesTerritoryID.';
    Comment Field [country_region_code] With 'ISO standard country or region code. Foreign key to CountryRegion.CountryRegionCode.';
    Comment Field [is_only_state_province_flag] With '0 = StateProvinceCode exists. 1 = StateProvinceCode unavailable, using CountryRegionCode.';
    Comment Field [name] With 'State or province description.';
    Comment Field [state_province_code] With 'ISO standard state or province code.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__state_provinces] Into [$(val__qvd_path__das)/raw__adventure_works__state_provinces.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__state_provinces];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__stores
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__stores.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [sales_person_id],
    [demographics],
    [name],
    [modified_date],
    [rowguid]
)
;

[raw__adventure_works__stores]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([sales_person_id]) As [sales_person_id],
    Text([demographics]) As [demographics],
    Text([name]) As [name],
    Text([modified_date]) As [modified_date],
    Text([rowguid]) As [rowguid]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__stores.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__stores'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__stores])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__stores] With 'Customers (resellers) of Adventure Works products.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key. Foreign key to Customer.BusinessEntityID.';
    Comment Field [sales_person_id] With 'ID of the sales person assigned to the customer. Foreign key to SalesPerson.BusinessEntityID.';
    Comment Field [demographics] With 'Demographic information about the store such as the number of employees, annual sales and store type.';
    Comment Field [name] With 'Name of the store.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';
    Comment Field [rowguid] With 'ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.';

    Trace Storing data...;
    Store [raw__adventure_works__stores] Into [$(val__qvd_path__das)/raw__adventure_works__stores.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__stores];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__transaction_histories
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__transaction_histories.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [reference_order_id],
    [reference_order_line_id],
    [transaction_id],
    [actual_cost],
    [quantity],
    [transaction_date],
    [transaction_type],
    [modified_date]
)
;

[raw__adventure_works__transaction_histories]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([reference_order_id]) As [reference_order_id],
    Text([reference_order_line_id]) As [reference_order_line_id],
    Text([transaction_id]) As [transaction_id],
    Text([actual_cost]) As [actual_cost],
    Text([quantity]) As [quantity],
    Text([transaction_date]) As [transaction_date],
    Text([transaction_type]) As [transaction_type],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__transaction_histories.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__transaction_histories'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__transaction_histories])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__transaction_histories] With 'Record of each purchase order, sales order, or work order transaction year to date.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [reference_order_id] With 'Purchase order, sales order, or work order identification number.';
    Comment Field [reference_order_line_id] With 'Line number associated with the purchase order, sales order, or work order.';
    Comment Field [transaction_id] With 'Primary key for TransactionHistory records.';
    Comment Field [actual_cost] With 'Product cost.';
    Comment Field [quantity] With 'Product quantity.';
    Comment Field [transaction_date] With 'Date and time of the transaction.';
    Comment Field [transaction_type] With 'W = WorkOrder, S = SalesOrder, P = PurchaseOrder.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__transaction_histories] Into [$(val__qvd_path__das)/raw__adventure_works__transaction_histories.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__transaction_histories];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__transaction_history_archives
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__transaction_history_archives.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [reference_order_id],
    [reference_order_line_id],
    [transaction_id],
    [actual_cost],
    [quantity],
    [transaction_date],
    [transaction_type],
    [modified_date]
)
;

[raw__adventure_works__transaction_history_archives]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([reference_order_id]) As [reference_order_id],
    Text([reference_order_line_id]) As [reference_order_line_id],
    Text([transaction_id]) As [transaction_id],
    Text([actual_cost]) As [actual_cost],
    Text([quantity]) As [quantity],
    Text([transaction_date]) As [transaction_date],
    Text([transaction_type]) As [transaction_type],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__transaction_history_archives.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__transaction_history_archives'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__transaction_history_archives])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__transaction_history_archives] With 'Transactions for previous years.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [reference_order_id] With 'Purchase order, sales order, or work order identification number.';
    Comment Field [reference_order_line_id] With 'Line number associated with the purchase order, sales order, or work order.';
    Comment Field [transaction_id] With 'Primary key for TransactionHistoryArchive records.';
    Comment Field [actual_cost] With 'Product cost.';
    Comment Field [quantity] With 'Product quantity.';
    Comment Field [transaction_date] With 'Date and time of the transaction.';
    Comment Field [transaction_type] With 'W = Work Order, S = Sales Order, P = Purchase Order.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__transaction_history_archives] Into [$(val__qvd_path__das)/raw__adventure_works__transaction_history_archives.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__transaction_history_archives];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__unit_measures
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__unit_measures.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [name],
    [unit_measure_code],
    [modified_date]
)
;

[raw__adventure_works__unit_measures]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([name]) As [name],
    Text([unit_measure_code]) As [unit_measure_code],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__unit_measures.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__unit_measures'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__unit_measures])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__unit_measures] With 'Unit of measure lookup table.';

    Trace Commenting fields...;
    Comment Field [name] With 'Unit of measure description.';
    Comment Field [unit_measure_code] With 'Primary key.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__unit_measures] Into [$(val__qvd_path__das)/raw__adventure_works__unit_measures.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__unit_measures];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__vendors
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__vendors.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [business_entity_id],
    [account_number],
    [active_flag],
    [credit_rating],
    [name],
    [preferred_vendor_status],
    [purchasing_web_service_url],
    [modified_date]
)
;

[raw__adventure_works__vendors]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([business_entity_id]) As [business_entity_id],
    Text([account_number]) As [account_number],
    Text([active_flag]) As [active_flag],
    Text([credit_rating]) As [credit_rating],
    Text([name]) As [name],
    Text([preferred_vendor_status]) As [preferred_vendor_status],
    Text([purchasing_web_service_url]) As [purchasing_web_service_url],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__vendors.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__vendors'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__vendors])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__vendors] With 'Companies from whom Adventure Works Cycles purchases parts or other goods.';

    Trace Commenting fields...;
    Comment Field [business_entity_id] With 'Primary key for Vendor records. Foreign key to BusinessEntity.BusinessEntityID.';
    Comment Field [account_number] With 'Vendor account (identification) number.';
    Comment Field [active_flag] With '0 = Vendor no longer used. 1 = Vendor is actively used.';
    Comment Field [credit_rating] With '1 = Superior, 2 = Excellent, 3 = Above average, 4 = Average, 5 = Below average.';
    Comment Field [name] With 'Company name.';
    Comment Field [preferred_vendor_status] With '0 = Do not use if another vendor is available. 1 = Preferred over other vendors supplying the same product.';
    Comment Field [purchasing_web_service_url] With 'Vendor URL.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__vendors] Into [$(val__qvd_path__das)/raw__adventure_works__vendors.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__vendors];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__work_order_routings
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__work_order_routings.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [location_id],
    [product_id],
    [work_order_id],
    [actual_cost],
    [actual_end_date],
    [actual_resource_hrs],
    [actual_start_date],
    [operation_sequence],
    [planned_cost],
    [scheduled_end_date],
    [scheduled_start_date],
    [modified_date]
)
;

[raw__adventure_works__work_order_routings]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([location_id]) As [location_id],
    Text([product_id]) As [product_id],
    Text([work_order_id]) As [work_order_id],
    Text([actual_cost]) As [actual_cost],
    Text([actual_end_date]) As [actual_end_date],
    Text([actual_resource_hrs]) As [actual_resource_hrs],
    Text([actual_start_date]) As [actual_start_date],
    Text([operation_sequence]) As [operation_sequence],
    Text([planned_cost]) As [planned_cost],
    Text([scheduled_end_date]) As [scheduled_end_date],
    Text([scheduled_start_date]) As [scheduled_start_date],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__work_order_routings.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__work_order_routings'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__work_order_routings])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__work_order_routings] With 'Work order details.';

    Trace Commenting fields...;
    Comment Field [location_id] With 'Manufacturing location where the part is processed. Foreign key to Location.LocationID.';
    Comment Field [product_id] With 'Primary key. Foreign key to Product.ProductID.';
    Comment Field [work_order_id] With 'Primary key. Foreign key to WorkOrder.WorkOrderID.';
    Comment Field [actual_cost] With 'Actual manufacturing cost.';
    Comment Field [actual_end_date] With 'Actual end date.';
    Comment Field [actual_resource_hrs] With 'Number of manufacturing hours used.';
    Comment Field [actual_start_date] With 'Actual start date.';
    Comment Field [operation_sequence] With 'Primary key. Indicates the manufacturing process sequence.';
    Comment Field [planned_cost] With 'Estimated manufacturing cost.';
    Comment Field [scheduled_end_date] With 'Planned manufacturing end date.';
    Comment Field [scheduled_start_date] With 'Planned manufacturing start date.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__work_order_routings] Into [$(val__qvd_path__das)/raw__adventure_works__work_order_routings.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__work_order_routings];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();

Trace
---------------------------------------------------------------
    Extracting raw__adventure_works__work_orders
---------------------------------------------------------------
;
Trace Setting variables...;
Let val__qvd_target = '$(val__qvd_path__das)/raw__adventure_works__work_orders.qvd';
Let val__target_qvd_exists = Not IsNull(QvdCreateTime('$(val__qvd_target)'));
Let val__incremental_value = '1970-01-01';

Trace Define hash table...;
[processed_record_hashes]:
Load
    Null() As [old_record_hash]
AutoGenerate 0
;

Trace Checking if target QVD exists...;
If $(val__target_qvd_exists) Then
    Trace Target found, loading hashes and max incremental value...;

    Concatenate([processed_record_hashes])
    Load
        [record_hash] As [old_record_hash]

    From
        [$(val__qvd_target)] (qvd)
    ;

    [max_incremental_value]:
    Load
        MAX([modified_date]) As [max_modified_date]
    From
        [$(val__qvd_target)] (qvd)
    ;

    Let val__incremental_value = Coalesce(Peek('max_modified_date', -1, 'max_incremental_value'), '$(val__incremental_value)');
    Drop Table [max_incremental_value];

Else
    Trace Target not found, starting full load...;

End If

Trace Loading new data with incremental value $(val__incremental_value)...;
Set var__record_hash = Hash256(
    [product_id],
    [scrap_reason_id],
    [work_order_id],
    [due_date],
    [end_date],
    [order_qty],
    [scrapped_qty],
    [start_date],
    [stocked_qty],
    [modified_date]
)
;

[raw__adventure_works__work_orders]:
Load
    *,
    $(var__record_hash) As [record_hash],
    Timestamp#('$(val__utc)', 'YYYY-MM-DD hh:mm:ss.ffffff') As [record_loaded_at]

Where
    Not Exists ([old_record_hash], $(var__record_hash))
;

Load
    Text([product_id]) As [product_id],
    Text([scrap_reason_id]) As [scrap_reason_id],
    Text([work_order_id]) As [work_order_id],
    Text([due_date]) As [due_date],
    Text([end_date]) As [end_date],
    Text([order_qty]) As [order_qty],
    Text([scrapped_qty]) As [scrapped_qty],
    Text([start_date]) As [start_date],
    Text([stocked_qty]) As [stocked_qty],
    Text([modified_date]) As [modified_date]

From
    [lib://OneDrive - mattias.thalen@two.se/Qlik/Analytical Data Storage System/data/das.raw__adventure_works__work_orders.parquet] (parquet)

Where
    Date([modified_date], 'YYYY-MM-DD') >= Date#('$(val__incremental_value)', 'YYYY-MM-DD')
;

Trace Dropping hash table...;
Drop Table [processed_record_hashes];

Trace Counting new records...;
Set val__no_of_new_records = Alt(NoOfRows('raw__adventure_works__work_orders'), 0);

Trace Checking if there are new records...;
If $(val__no_of_new_records) > 0 Then

    Trace Checking if target QVD exists...;
    If $(val__target_qvd_exists) Then
        Trace Appending previously ingested data...;

        Concatenate([raw__adventure_works__work_orders])
        Load * From [$(val__qvd_target)] (qvd) Where Not Exists ([record_hash]);

    Else
        Trace Target not found, skipping append...;

    End If

    Trace Commenting table...;
    Comment Table [raw__adventure_works__work_orders] With 'Manufacturing work orders.';

    Trace Commenting fields...;
    Comment Field [product_id] With 'Product identification number. Foreign key to Product.ProductID.';
    Comment Field [scrap_reason_id] With 'Reason for inspection failure.';
    Comment Field [work_order_id] With 'Primary key for WorkOrder records.';
    Comment Field [due_date] With 'Work order due date.';
    Comment Field [end_date] With 'Work order end date.';
    Comment Field [order_qty] With 'Product quantity to build.';
    Comment Field [scrapped_qty] With 'Quantity that failed inspection.';
    Comment Field [start_date] With 'Work order start date.';
    Comment Field [stocked_qty] With 'Quantity built and put in inventory.';
    Comment Field [modified_date] With 'Date and time the record was last updated.';

    Trace Storing data...;
    Store [raw__adventure_works__work_orders] Into [$(val__qvd_path__das)/raw__adventure_works__work_orders.qvd] (qvd);

    Trace Dropping table...;
    Drop Table [raw__adventure_works__work_orders];

Else
    Trace No new records found, skipping append...;

End If

Trace Resetting variables...;
Let val__qvd_target = Null();
Let val__target_qvd_exists = Null();
Let val__incremental_value = Null();
Let var__record_hash = Null();
Let val__no_of_new_records = Null();
